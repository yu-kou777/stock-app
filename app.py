import streamlit as st
import yfinance as yf
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor

# ==========================================
# ğŸ›¡ï¸ éŠ˜æŸ„ãƒã‚¹ã‚¿
# ==========================================
NAME_MAP = {
    "7203.T": "ãƒˆãƒ¨ã‚¿", "9984.T": "SBG", "8306.T": "ä¸‰è±UFJ", "6758.T": "ã‚½ãƒ‹ãƒ¼G",
    "6098.T": "ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ", "8035.T": "æ±ã‚¨ãƒ¬ã‚¯", "4063.T": "ä¿¡è¶ŠåŒ–å­¦", "7974.T": "ä»»å¤©å ‚",
    "6701.T": "NEC", "4901.T": "å¯Œå£«ãƒ•ã‚¤ãƒ«ãƒ ", "6330.T": "æ±æ´‹ã‚¨ãƒ³ã‚¸", "5406.T": "ç¥æˆ¸é‹¼",
    "8151.T": "æ±é™½ãƒ†ã‚¯", "9101.T": "æ—¥æœ¬éƒµèˆ¹", "4661.T": "OLC", "5401.T": "æ—¥æœ¬è£½é‰„"
}

# ==========================================
# ğŸŒ æ±ºç®—æ—¥ãƒã‚§ãƒƒã‚¯ (æ ªæ¢)
# ==========================================
def scrape_earnings_date(code):
    clean_code = code.replace(".T", "")
    url = f"https://kabutan.jp/stock/finance?code={clean_code}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        target = soup.find(string=re.compile(r"æ±ºç®—ç™ºè¡¨äºˆå®šæ—¥"))
        if target:
            match = re.search(r"(\d{2}/\d{2}/\d{2})", str(target.parent.get_text()))
            if match: return datetime.strptime("20" + match.group(1), "%Y/%m/%d").date()
    except: pass
    return None

# ==========================================
# ğŸ•¯ï¸ ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š (åè»¢ãƒ»ç¶™ç¶šãƒ»ä¿ã¡åˆã„)
# ==========================================
def detect_complex_patterns(df, rsi):
    if len(df) < 30: return None, 0, "neutral"
    close, high, low, open_p = df['Close'], df['High'], df['Low'], df['Open']
    curr_price = close.iloc[-1]

    # --- 1. ç¶™ç¶šï¼šãƒ•ãƒ©ãƒƒã‚° ---
    if all(high.iloc[i] < high.iloc[i-1] for i in range(-3, 0)) and \
       (high.tail(5).max() - low.tail(5).min()) < (curr_price * 0.04):
        return "ğŸš©ãƒ•ãƒ©ãƒƒã‚°(ä¸Šæ˜‡ä¸­ç¶™)", 75, "buy"

    # --- 2. ä¿ã¡åˆã„ï¼šã‚¹ã‚¯ã‚¨ã‚¢ ---
    if (high.tail(10).max() - low.tail(10).min()) / curr_price < 0.03:
        return "ğŸ“¦ã‚¹ã‚¯ã‚¨ã‚¢(ä¿ã¡åˆã„)", 65, "neutral"

    # --- 3. åè»¢ï¼šä¸‰ç©º / æ˜ã‘ã®æ˜æ˜Ÿ / é€†ä¸‰å°Š ---
    if rsi < 60:
        if all(high.iloc[i] < low.iloc[i-1] for i in range(-3, 0)): return "ğŸ”¥ä¸‰ç©ºå©ãè¾¼ã¿", 100, "buy"
        if (close.iloc[-3] < open_p.iloc[-3] and close.iloc[-1] > open_p.iloc[-1]): return "ğŸŒ…æ˜ã‘ã®æ˜æ˜Ÿ", 90, "buy"
        l_vals = low.tail(15).values
        if l_vals.min() == l_vals[5:10].min() and l_vals[0:5].min() > l_vals[5:10].min(): return "ğŸ’é€†ä¸‰å°Š", 80, "buy"

    # --- 4. å£²ã‚Šï¼šä¸‰å°Š / é™°ã®åŒ…ã¿è¶³ ---
    if rsi > 40:
        h_vals = high.tail(15).values
        if h_vals.max() == h_vals[5:10].max() and h_vals[0:5].max() < h_vals[5:10].max(): return "ğŸ’€ä¸‰å°Š(å¤©äº•)", 85, "sell"
        if (close.iloc[-2] > open_p.iloc[-2] and close.iloc[-1] < open_p.iloc[-2]): return "ğŸ“‰é™°ã®åŒ…ã¿è¶³", 70, "sell"

    return None, 0, "neutral"

# ==========================================
# ğŸ§  ç²¾å¯†åˆ†æãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def get_analysis_data(ticker, name, min_p=0, max_p=10000000):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="1y") # ä½™è£•ã‚’æŒã£ã¦1å¹´åˆ†å–å¾—
        if len(hist) < 60: return None
        curr_price = int(hist["Close"].iloc[-1])
        if not (min_p <= curr_price <= max_p): return None

        # MACD
        ema12 = hist['Close'].ewm(span=12, adjust=False).mean()
        ema26 = hist['Close'].ewm(span=26, adjust=False).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9, adjust=False).mean()
        golden_cross = (macd.iloc[-2] < signal.iloc[-2]) and (macd.iloc[-1] > signal.iloc[-1])
        dead_cross = (macd.iloc[-2] > signal.iloc[-2]) and (macd.iloc[-1] < signal.iloc[-1])

        # RSI
        delta = hist['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rsi = 100 - (100 / (1 + (gain / loss))).iloc[-1]

        # åºŠ (åè»¢äºˆæ¸¬)
        ma20 = hist['Close'].rolling(20).mean()
        std20 = hist['Close'].rolling(20).std()
        floor = max(int(ma20.iloc[-1] - (std20.iloc[-1] * 2)), int(hist['Low'].tail(60).min()))

        # ãƒ‘ã‚¿ãƒ¼ãƒ³
        p_name, p_score, sig_type = detect_complex_patterns(hist, rsi)
        
        # æ±ºç®—ãƒªã‚¹ã‚¯
        earn_date = scrape_earnings_date(ticker)
        days = (earn_date - datetime.now().date()).days if earn_date else 999
        is_risk = (0 <= days <= 3)
        is_earn_short = (0 <= days <= 14) and (rsi > 70 or curr_price > ma20.iloc[-1] * 1.07)

        # ã‚¹ã‚³ã‚¢ (MACD GCã‚’é‡è¦–)
        buy_score = 0
        if not is_risk:
            if rsi < 50: buy_score += 20
            if golden_cross: buy_score += 50
            if sig_type == "buy": buy_score += p_score

        return {
            "ã‚³ãƒ¼ãƒ‰": ticker.replace(".T", ""), "éŠ˜æŸ„å": name, "ç¾åœ¨å€¤": curr_price,
            "RSI": round(rsi, 1), "MACD": "GC(è²·ã„)" if golden_cross else "DC(å£²ã‚Š)" if dead_cross else "ç¶™ç¶š",
            "ãƒ•ãƒ­ã‚¢": floor, "ã‚¨ãƒ³ãƒˆãƒªãƒ¼": int(floor * 1.01),
            "ãƒ‘ã‚¿ãƒ¼ãƒ³": p_name if p_name else "ãªã—", "åˆ©ç¢ºç›®æ¨™": int(hist['High'].tail(25).max()),
            "æåˆ‡ç›®å®‰": int(floor * 0.97), "æ±ºç®—": earn_date if earn_date else "æœªå®š",
            "is_risk": is_risk, "is_earn_short": is_earn_short, "buy_score": buy_score
        }
    except: return None

# ==========================================
# ğŸ‡ ãƒ‡ã‚¤ãƒˆãƒ¬ç”¨ (5åˆ†è¶³)
# ==========================================
def get_day_data(ticker):
    try:
        hist = yf.Ticker(ticker).history(period="5d", interval="5m")
        if len(hist) < 20: return None
        last_dt = hist.index[-1].astimezone(timezone(timedelta(hours=9)))
        curr = int(hist["Close"].iloc[-1])
        ma20 = hist['Close'].rolling(20).mean().iloc[-1]
        return {
            "ç¾åœ¨å€¤": curr, "å‹¢ã„": "âš¡ä¸Šæ˜‡" if curr > ma20 else "âš¡ä¸‹è½",
            "åˆ©ç¢º": int(curr * 1.015), "æåˆ‡": int(curr * 0.99), "æ™‚åˆ»": last_dt.strftime('%H:%M')
        }
    except: return None

# ==========================================
# ğŸ“± ã‚¢ãƒ—ãƒªç”»é¢
# ==========================================
st.set_page_config(page_title="æœ€å¼·æ ªã‚¹ã‚­ãƒ£ãƒŠãƒ¼ãƒ»çœŸãƒ»æœ€çµ‚ç‰ˆ", layout="wide")
st.title("ğŸ¦… æœ€å¼·æ ªã‚¹ã‚­ãƒ£ãƒŠãƒ¼ (å…¨æ©Ÿèƒ½ãƒ»å…¨ã‚·ã‚°ãƒŠãƒ«çµ±åˆç‰ˆ)")

code_in = st.text_input("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›", "").strip()
if code_in:
    full_c = code_in + ".T" if ".T" not in code_in else code_in
    res = get_analysis_data(full_c, NAME_MAP.get(full_c, code_in))
    day = get_day_data(full_c)
    if res:
        if res["is_risk"]: st.error(f"ğŸ›‘ å–å¼•ç¦æ­¢ï¼šæ±ºç®—ç™ºè¡¨({res['æ±ºç®—']})ãŒç›´å‰ã§ã™ã€‚")
        elif res["is_earn_short"]: st.warning(f"ğŸ’€ ç©ºå£²ã‚Šæ³¨ç›®ï¼šæ±ºç®—å‰ã®ç•°å¸¸ãªéç†±ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚")
        
        tab1, tab2 = st.tabs(["ğŸ¢ ã‚¹ã‚¤ãƒ³ã‚° (åè»¢ãƒ»ç¶™ç¶š)", "ğŸ‡ ãƒ‡ã‚¤ãƒˆãƒ¬ (ç¬é–“)"])
        with tab1:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç¾åœ¨å€¤", f"{res['ç¾åœ¨å€¤']}å††")
                st.info(f"ğŸ›¡ï¸ åè»¢äºˆæƒ³ãƒ•ãƒ­ã‚¢: {res['ãƒ•ãƒ­ã‚¢']}å††")
            with col2:
                st.success(f"æŒ‡å€¤ç›®å®‰: {res['ã‚¨ãƒ³ãƒˆãƒªãƒ¼']}å††")
                st.metric("åˆ©ç¢ºç›®æ¨™", f"{res['åˆ©ç¢ºç›®æ¨™']}å††")
                st.metric("æåˆ‡ç›®å®‰", f"{res['æåˆ‡ç›®å®‰']}å††", delta_color="inverse")
            with col3:
                st.write(f"åˆ¤å®š: **{'è²·ã„æ¨å¥¨ ğŸš€' if res['buy_score']>=70 else 'æ§˜å­è¦‹ â˜•'}**")
                st.write(f"å‡ºç¾ã‚µã‚¤ãƒ³: **{res['ãƒ‘ã‚¿ãƒ¼ãƒ³']}**")
                st.write(f"MACD: **{res['MACD']}** / RSI: **{res['RSI']}**")
        with tab2:
            if day:
                st.metric(f"5åˆ†è¶³å‹¢ã„ ({day['æ™‚åˆ»']})", day['å‹¢ã„'], delta=f"{day['ç¾åœ¨å€¤']}å††")
                st.write(f"ğŸ¯ ç¬é–“åˆ©ç¢º: {day['åˆ©ç¢º']}å†† / ğŸ›‘ ç¬é–“æåˆ‡: {day['æåˆ‡']}å††")

st.divider()

if st.button("å…¨éŠ˜æŸ„ã‚’ä¸€æ–‰ã‚¹ã‚­ãƒ£ãƒ‹ãƒ³ã‚°", use_container_width=True):
    with ThreadPoolExecutor(max_workers=5) as ex:
        fs = [ex.submit(get_analysis_data, t, n) for t, n in NAME_MAP.items()]
        ds = [f.result() for f in fs if f.result()]
    if ds:
        df = pd.DataFrame(ds)
        # ğŸ’€ æ±ºç®—ç©ºå£²ã‚Š
        shorts = df[df["is_earn_short"] == True]
        if not shorts.empty:
            st.subheader("ğŸ’€ æ±ºç®—å‰ãƒ»éç†±ç©ºå£²ã‚Šå€™è£œ")
            st.dataframe(shorts[["ã‚³ãƒ¼ãƒ‰","éŠ˜æŸ„å","ç¾åœ¨å€¤","RSI","æ±ºç®—","åˆ©ç¢ºç›®æ¨™"]].rename(columns={"åˆ©ç¢ºç›®æ¨™":"ç©ºå£²ã‚Šç›®æ¨™"}), hide_index=True)
        # ğŸ”¥ è²·ã„æ¨å¥¨
        st.subheader("ğŸ”¥ è²·ã„æ¨å¥¨ (ç¾ç‰©ãƒ»ä¿¡ç”¨è²·ã„)")
        buys = df[df["buy_score"] >= 70].sort_values("buy_score", ascending=False)
        st.dataframe(buys[["ã‚³ãƒ¼ãƒ‰","éŠ˜æŸ„å","ç¾åœ¨å€¤","RSI","MACD","ãƒ‘ã‚¿ãƒ¼ãƒ³","åˆ©ç¢ºç›®æ¨™","æåˆ‡ç›®å®‰"]], hide_index=True)
    else: st.warning("ç¾åœ¨ã€æ¨å¥¨éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
